{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oolonglilfox/CSC2516Project/blob/main/csc413_group200_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKmtLD7xue_D"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmvwsT_s43qW",
        "outputId": "1196c49b-d3cf-4e26-d057-140302a61397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.11-py2.py3-none-any.whl (628 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.1/628.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Downloading cleverhans-4.0.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from kornia) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kornia) (23.0)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.10.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.10)\n",
            "Collecting pycodestyle\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from cleverhans) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.22.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from cleverhans) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.9/dist-packages (from cleverhans) (0.19.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (3.25.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (5.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->cleverhans) (0.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability->cleverhans) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability->cleverhans) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability->cleverhans) (0.1.8)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->cleverhans) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans, kornia\n",
            "Successfully installed cleverhans-4.0.0 kornia-0.6.11 mnist-0.2.2 nose-1.3.7 pycodestyle-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install kornia cleverhans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "47aI9EMYKFH2"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import torch.utils.data.dataloader as Data\n",
        "import torch.nn as nn\n",
        "from torch.nn import DataParallel\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models, datasets\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import io\n",
        "import kornia\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
        "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9usS12YjNU5d",
        "outputId": "ca4ac27f-6e3d-4609-d374-2c050696b17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VnXR871J4z2"
      },
      "source": [
        "# Model Building\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WbiobqGKKdgp"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "   # define basic building block of a ResNet - a two-layer convolutiona neural network with a residual connection\n",
        "    expansion = 1 # class-level variable\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # define the 2 convolutional layers with batch normalization\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # define shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # building block needed in the ResNet architecture\n",
        "    expansion = 4 # adjust number of output channels in residual branch of the block\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class denoising_block(nn.Module):\n",
        "    def __init__(self, in_planes, ksize, filter_type):\n",
        "        super(denoising_block, self).__init__()\n",
        "        self.in_planes = in_planes\n",
        "        self.ksize = ksize\n",
        "        self.filter_type = filter_type\n",
        "        self.conv = nn.Conv2d(in_channels=in_planes, out_channels=in_planes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.filter_type == 'Median_Filter':\n",
        "            x_denoised = kornia.filters.median_blur(x, (self.ksize, self.ksize))\n",
        "        elif self.filter_type == 'Mean_Filter':\n",
        "            x_denoised = kornia.filters.box_blur(x, (self.ksize, self.ksize))\n",
        "        elif self.filter_type == 'Gaussian_Filter':\n",
        "            x_denoised = kornia.filters.gaussian_blur2d(x, (self.ksize, self.ksize), (0.3 * ((x.shape[3] - 1) * 0.5 - 1) + 0.8, 0.3 * ((x.shape[2] - 1) * 0.5 - 1) + 0.8))\n",
        "        new_x = x + self.conv(x_denoised)\n",
        "        return new_x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        if whether_denoising:\n",
        "            self.denoising_block1 = denoising_block(in_planes=64, ksize=ksize, filter_type=filter_type)\n",
        "            self.denoising_block2 = denoising_block(in_planes=64, ksize=ksize, filter_type=filter_type)\n",
        "        self.whether_denoising = whether_denoising\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        if self.whether_denoising:\n",
        "            out = self.denoising_block1(out)\n",
        "        out = self.layer1(out)\n",
        "        if self.whether_denoising:\n",
        "            out = self.denoising_block2(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtaeqxsZQauQ"
      },
      "outputs": [],
      "source": [
        "def ResNet18(whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=10, whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "def ResNet34(whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=10, whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "def ResNet50(whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=10, whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "def ResNet101(whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=10, whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "def ResNet152(whether_denoising=False, filter_type=\"Mean_Filter\", ksize=3):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], num_classes=10, whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "def test():\n",
        "    from torch.autograd import Variable\n",
        "    net = ResNet18(whether_denoising=True, filter_type=\"Median_Filter\", ksize=3)\n",
        "    x = Variable(torch.randn(1, 3, 32, 32), requires_grad=True)\n",
        "    y = net(x)\n",
        "    print(y)\n",
        "\n",
        "def denoising_block_test(filter_type):\n",
        "    from torch.autograd import Variable\n",
        "    denoising_block1 = denoising_block(in_planes=32, ksize=3, filter_type=filter_type)\n",
        "    x = Variable(torch.ones(2, 64, 32, 32), requires_grad=True)\n",
        "    y = denoising_block1(x)\n",
        "    print(y)\n",
        "    y.backward(x)\n",
        "    print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59W_TSWLFbzo"
      },
      "source": [
        "# Data transformation\n",
        "Countering Adversarial Images Using Input Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qUtIkGU3F_XH"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def denoise_tv_bregman(image, weight, max_iter=100, eps=1e-3):\n",
        "  if image.is_cuda:\n",
        "    image = image.cpu()\n",
        "  image = atleast_3d(image)\n",
        "\n",
        "  img_shape = list(image.shape)\n",
        "  rows = img_shape[0]\n",
        "  rows2 = rows + 2\n",
        "  cols = img_shape[1]\n",
        "  cols2 = cols + 2\n",
        "  dims = img_shape[2]\n",
        "  total = rows * cols * dims\n",
        "  shape_extend = (rows2, cols2, dims)\n",
        "  # out is firstly created as zeros-like tensor with size as shape_extend\n",
        "  out = torch.zeros(shape_extend, dtype=torch.float)\n",
        "\n",
        "  dx = out.clone().detach()\n",
        "  dy = out.clone().detach()\n",
        "  bx = out.clone().detach()\n",
        "  by = out.clone().detach()\n",
        "\n",
        "  lam = 2 * weight\n",
        "  rmse = float(\"inf\")\n",
        "  norm = (weight + 4 * lam)\n",
        "\n",
        "  out_rows, out_cols = out.shape[:2]\n",
        "  out[1:out_rows-1, 1:out_cols-1] = image\n",
        "\n",
        "  out = fill_extend(image, out)\n",
        "\n",
        "  i = 0\n",
        "  regularization = torch.mul(image, weight)\n",
        "  # iterative optimization method\n",
        "  # split-Bregman iteration\n",
        "  while i < max_iter and rmse > eps:\n",
        "    uprev = out[1:-1, 1:-1, :]\n",
        "\n",
        "    ux = out[1:-1, 2:, :] - uprev\n",
        "    uy = out[2:, 1:-1, :] - uprev\n",
        "\n",
        "    unew = torch.div(\n",
        "        (torch.mul((out[2:, 1:-1, :]\n",
        "                + out[0:-2, 1:-1, :]\n",
        "                + out[1:-1, 2:, :]\n",
        "                + out[1:-1, 0:-2, :]\n",
        "\n",
        "                + dx[1:-1, 0:-2, :]\n",
        "                - dx[1:-1, 1:-1, :]\n",
        "                + dy[0:-2, 1:-1, :]\n",
        "                - dy[1:-1, 1:-1, :]\n",
        "\n",
        "                - bx[1:-1, 0:-2, :]\n",
        "                + bx[1:-1, 1:-1, :]\n",
        "                - by[0:-2, 1:-1, :]\n",
        "                + by[1:-1, 1:-1, :]), lam) + regularization),\n",
        "          norm)\n",
        "    out[1:-1, 1:-1, :] = unew.clone().detach()\n",
        "\n",
        "    rmse = torch.norm(unew-uprev, p=2)\n",
        "\n",
        "    bxx = bx[1:-1, 1:-1, :].clone().detach()\n",
        "    byy = by[1:-1, 1:-1, :].clone().detach()\n",
        "\n",
        "    tx = ux + bxx\n",
        "    ty = uy + byy\n",
        "    s = torch.sqrt(torch.pow(tx, 2)+torch.pow(ty, 2))\n",
        "    dxx = torch.div(torch.addcmul(torch.zeros(s.shape, dtype=torch.float), lam, s, tx),\n",
        "                    torch.add(torch.mul(s, lam), 1))\n",
        "    dyy = torch.div(torch.addcmul(torch.zeros(s.shape, dtype=torch.float), lam, s, ty),\n",
        "                    torch.add(torch.mul(s, lam), 1))\n",
        "\n",
        "    dx[1:-1, 1:-1, :] = dxx.clone().detach()\n",
        "    dy[1:-1, 1:-1, :] = dyy.clone().detach()\n",
        "\n",
        "    bx[1:-1, 1:-1, :] += ux - dxx\n",
        "    by[1:-1, 1:-1, :] += uy - dyy\n",
        "\n",
        "    i += 1\n",
        "  # return the denoised image excluding the extended area\n",
        "  return out[1:-1, 1:-1]\n",
        "\n",
        "def atleast_3d(image):\n",
        "    dim = list(image.shape)\n",
        "\n",
        "    if len(dim) >= 3:\n",
        "        return image\n",
        "    else:\n",
        "        dim.append(1)\n",
        "        return image.view(dim)\n",
        "\n",
        "def fill_extend(image, out):\n",
        "    \"\"\"fill the extended area in out img with original img\"\"\"\n",
        "    out_rows, out_cols = out.shape[:2]\n",
        "    rows, cols = out_rows - 2, out_cols - 2\n",
        "    out[0, 1:out_cols-1] = image[1, :]\n",
        "    out[1:out_rows-1, 0] = image[:, 1]\n",
        "    out[out_rows-1, 1:out_cols-1] = image[rows-1, :]\n",
        "    out[1:out_rows-1, out_cols-1] = image[:, cols-1]\n",
        "    return out\n",
        "\n",
        "def randomJPEGcompression(image):\n",
        "    qf = np.random.randint(10, 101)\n",
        "    if torch.is_tensor(image):\n",
        "      image = transforms.ToPILImage()(image)\n",
        "    outputIoStream = io.BytesIO()\n",
        "    \n",
        "    image.save(outputIoStream, \"JPEG\", quality=qf, optimice=True)\n",
        "    outputIoStream.seek(0)\n",
        "    return Image.open(outputIoStream)\n",
        "\n",
        "def tvDenoising(image):\n",
        "  return denoise_tv_bregman(image, weight=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "V-5HM7gSHp9S"
      },
      "outputs": [],
      "source": [
        "image_transforms = {\n",
        "  'cropping_rescaling':\n",
        "  transforms.Compose([\n",
        "      transforms.RandomResizedCrop(size=32),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      # transforms.RandomHorizontalFlip(),\n",
        "      # transforms.ToTensor(),\n",
        "      # transforms.Normalize([0.485, 0.456, 0.406],\n",
        "      #                       [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "  ]),\n",
        "  'bit_depth_reduction':\n",
        "  transforms.Compose([\n",
        "      transforms.RandomPosterize(4, p=0.5),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      # transforms.RandomHorizontalFlip(),\n",
        "      # transforms.ToTensor(),\n",
        "      # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'JEPG_compression':\n",
        "  transforms.Compose([\n",
        "      transforms.Lambda(randomJPEGcompression),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      # transforms.RandomHorizontalFlip(),\n",
        "      # transforms.ToTensor(),\n",
        "      # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'TVDenoise':\n",
        "  transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Lambda(tvDenoising),\n",
        "      transforms.ToPILImage()\n",
        "      # transforms.RandomRotation(degrees=15),\n",
        "      # transforms.RandomHorizontalFlip(),\n",
        "      # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'cropping_rescaling_attack':\n",
        "  transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.RandomResizedCrop(size=32),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                            [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "  ]),\n",
        "  'bit_depth_reduction_attack':\n",
        "  transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.RandomPosterize(4, p=0.5),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'JEPG_compression_attack':\n",
        "  transforms.Compose([\n",
        "      transforms.Lambda(randomJPEGcompression),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'TVDenoise_attack':\n",
        "  transforms.Compose([\n",
        "      transforms.Lambda(tvDenoising),\n",
        "      transforms.RandomRotation(degrees=15),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI3fCNuHKXDF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rm9YY_lnKbSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c5c169-14db-4328-c7ea-725274ffd8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/eva_share/datasets/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 104345533.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /home/eva_share/datasets/cifar10/cifar-10-python.tar.gz to /home/eva_share/datasets/cifar10\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "whether_denoising=True\n",
        "filter_type='Mean_Filter'\n",
        "ksize=3\n",
        "learning_rate=1e-3\n",
        "epochs=20\n",
        "batch_size=64\n",
        "num_workers=32\n",
        "GPU='0'\n",
        "# model_address = \"/content/drive/MyDrive/Colab Notebooks/TrueMean_Filter3.pkl\"\n",
        "basic_model = 'ResNet18'\n",
        "filter_type = 'Mean_Filter'\n",
        "kernel_size = 3\n",
        "perturbation_threshold = 1e-8\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.9\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU\n",
        "def test(model, testloader, criterion):\n",
        "    model.eval()\n",
        "    correct, total, loss, counter = 0, 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in testloader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            counter += 1\n",
        "    return loss / total, correct / total\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='/home/eva_share/datasets/cifar10', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=32)\n",
        "\n",
        "\n",
        "def train(whether_denoising, filter_type, ksize, epochs, transform=None):\n",
        "  if transform:\n",
        "    transform_train = image_transforms[transform]\n",
        "\n",
        "  else:\n",
        "    # Set the transformation\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "\n",
        "  # Load the dataset\n",
        "  trainset = torchvision.datasets.CIFAR10(root='/home/eva_share/datasets/cifar10', train=True, download=True, transform=transform_train)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=32)\n",
        "  \n",
        "  classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "  # Establish the model\n",
        "  model = ResNet18(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "  model = model.cuda()\n",
        "  model = nn.DataParallel(model)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  params = list(model.parameters())\n",
        "  optimizer = optim.SGD(params, lr=learning_rate, weight_decay=1e-4, momentum=0.9, nesterov=True)\n",
        "  scheduler = MultiStepLR(optimizer, milestones=[int(epochs/2), int(epochs*3/4), int(epochs*7/8)], gamma=0.1)\n",
        "\n",
        "  total, correct, train_loss = 0, 0, 0\n",
        "  best_acc, best_epoch = 0, 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for i, data in enumerate(tqdm(trainloader)):\n",
        "          model.train()\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.cuda()\n",
        "          labels = labels.cuda()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # count acc,loss on trainset\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.shape[0]\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          train_loss += loss.item()\n",
        "      \n",
        "      acc = correct / total\n",
        "      train_loss /= total\n",
        "      val_loss, val_acc = test(model, testloader, criterion)\n",
        "      \n",
        "      print(\"epoch:{}, train_loss:{:.3f}, train_acc:{:.3f}, val_loss:{:.3f}, val_acc:{:.3f}\".format(epoch, train_loss, acc, val_loss, val_acc))\n",
        "      correct, total, train_loss = 0, 0, 0\n",
        "      if best_acc < val_acc:\n",
        "          best_acc = val_acc\n",
        "          best_epoch = epoch\n",
        "          torch.save(model.state_dict(),\"/content/drive/MyDrive/Colab Notebooks/\" + str(whether_denoising) + filter_type + str(transform) + '.pkl')\n",
        "  print(\"Best model at present: val_acc={:.3f}  best_epoch={}\".format(best_acc, best_epoch))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sb_6QUXROFZ"
      },
      "source": [
        "# Adversarial Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "neZxfT-jIMpG"
      },
      "outputs": [],
      "source": [
        "def evaluate_attack(testset, attack_method, norm, epsilon, model, transform=None):\n",
        "    # load dataset\n",
        "    test_loader = testset\n",
        "\n",
        "    # run evaluation\n",
        "    model.eval()\n",
        "  \n",
        "    correct = 0.0\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "      if attack_method == 'baseline' or epsilon == 0.0:\n",
        "          pass\n",
        "      elif attack_method == 'fgsm':\n",
        "          images = fast_gradient_method(\n",
        "              model_fn=model,\n",
        "              x=images,\n",
        "              eps=epsilon,\n",
        "              norm=norm,\n",
        "              clip_min=0.0,\n",
        "              clip_max=255,\n",
        "          )\n",
        "\n",
        "      if transform == None:\n",
        "        with torch.no_grad():\n",
        "            out = model(images)\n",
        "            _, preds = torch.max(out, 1)\n",
        "            correct += torch.sum(preds == labels).detach().cpu()\n",
        "      else:\n",
        "        transform_methods=image_transforms[transform]\n",
        "        for img in images:\n",
        "          img = transform_methods(img)\n",
        "        with torch.no_grad():\n",
        "            out = model(images)\n",
        "            _, preds = torch.max(out, 1)\n",
        "            correct += torch.sum(preds == labels).detach().cpu()\n",
        "\n",
        "\n",
        "      acc = correct / len(test_loader.dataset)\n",
        "  \n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gswRx3zups2m"
      },
      "outputs": [],
      "source": [
        "def load_model(basic_model, whether_denoising, filter_type, ksize):\n",
        "    if basic_model == 'ResNet18':\n",
        "        model = ResNet18(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "    elif basic_model == 'ResNet34':\n",
        "        model = ResNet34(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "    elif basic_model == 'ResNet50':\n",
        "        model = ResNet50(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "    elif basic_model == 'ResNet101':\n",
        "        model = ResNet101(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "    elif basic_model == 'ResNet152':\n",
        "        model = ResNet152(whether_denoising=whether_denoising, filter_type=filter_type, ksize=ksize)\n",
        "\n",
        "    model.cuda()\n",
        "    model = DataParallel(model)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ_W5QnaArHK"
      },
      "source": [
        "# Plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JHWtRw7XBknV"
      },
      "outputs": [],
      "source": [
        "def plottingAttack(modelsInfo, epsilon_range, testloader):\n",
        "  epsilons = np.linspace(epsilon_range[0], epsilon_range[1], 10)\n",
        "  os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU\n",
        "  for info in modelsInfo:\n",
        "    model = load_model(basic_model=basic_model, \n",
        "                       whether_denoising=info['whether_denoising'], \n",
        "                       filter_type=info['filter_type'], ksize=kernel_size)\n",
        "    model.load_state_dict(torch.load(info['address']))\n",
        "    model.cuda()\n",
        "    model = nn.DataParallel(model)\n",
        "    attack_acc = []\n",
        "    plt.xlabel('epsilon')\n",
        "    plt.ylabel('test_acc')\n",
        "    for eps in tqdm(epsilons):\n",
        "      if info['transform']:\n",
        "        attack_acc.append(evaluate_attack(testloader, 'fgsm', 2, eps, model, transform = info['transform']+\"_attack\"))\n",
        "      else:\n",
        "        attack_acc.append(evaluate_attack(testloader, 'fgsm', 2, eps, model))\n",
        "    if info['whether_denoising'] and info['transform']:\n",
        "      label = info['filter_type'] + \"+\" + info['transform']\n",
        "    elif info['whether_denoising'] :\n",
        "      label = info['filter_type'] \n",
        "    elif info['transform']:\n",
        "      label = info['transform']\n",
        "    else:\n",
        "      label = 'Baseline'\n",
        "    plt.plot(epsilons, attack_acc, label = label)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = train(True,filter_type,ksize,\"\")"
      ],
      "metadata": {
        "id": "DvSImUQjgZin"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(basic_model=basic_model, \n",
        "                   whether_denoising=False, \n",
        "                   filter_type=filter_type, ksize=kernel_size)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterNone.pkl'))\n",
        "model.cuda()\n",
        "model = nn.DataParallel(model)\n",
        "evaluate_attack(testloader, 'fgsm', 2, 0.5, model, transform = None)"
      ],
      "metadata": {
        "id": "LHXZz1RflyVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0453c5dd-81a7-4a53-d1e6-c11ef8e7cb77"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5464)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(basic_model=basic_model, \n",
        "                   whether_denoising=False, \n",
        "                   filter_type=filter_type, ksize=kernel_size)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterNone.pkl'))\n",
        "model.cuda()\n",
        "model = nn.DataParallel(model)\n",
        "evaluate_attack(testloader, 'fgsm', 2, 0.5, model, 'TVDenoise_attack')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyQ3_-IrXl3b",
        "outputId": "a336bbd2-695e-4c9e-b4f6-3a51512551dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5464)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='/home/eva_share/datasets/cifar10', train=True, download=True)\n",
        "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
        "orig_img = testset[1][0]\n",
        "# if you change the seed, make sure that the randomly-applied transforms\n",
        "# properly show that the image can be both transformed and *not* transformed!\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
        "    if not isinstance(imgs[0], list):\n",
        "        # Make a 2d grid even if there's just 1 row\n",
        "        imgs = [imgs]\n",
        "\n",
        "    num_rows = len(imgs)\n",
        "    num_cols = len(imgs[0])\n",
        "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
        "    for row_idx, row in enumerate(imgs):\n",
        "       \n",
        "        for col_idx, img in enumerate(row):\n",
        "            ax = axs[row_idx, col_idx]\n",
        "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
        "            ax.set(title=row_title[col_idx])\n",
        "            ax.title.set_size(8)\n",
        "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "    # if with_orig:\n",
        "    #     axs[0, 0].set(title='Original image')\n",
        "    #     axs[0, 0].title.set_size(8)\n",
        "    # if row_title is not None:\n",
        "    #     for row_idx in range(num_rows):\n",
        "    #         axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "row_title = ['Oriniginal','Cropping_rescaling', 'Bit_depth_reduction','JEPG_compression','TVDenoise' ]\n",
        "img1 = image_transforms['cropping_rescaling'](orig_img)\n",
        "img2 = image_transforms['bit_depth_reduction'](orig_img)\n",
        "img3 = image_transforms['JEPG_compression'](orig_img)\n",
        "img4 = image_transforms['TVDenoise'](orig_img)\n",
        "\n",
        "\n",
        "plot([orig_img,img1,img2,img3,img4],row_title=row_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "zANg014uwIBc",
        "outputId": "129820a9-06c3-4b9c-e190-2484cffa8446"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qLXXPtF0PKpY"
      },
      "outputs": [],
      "source": [
        "# modelsInfo = [{'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': None,\n",
        "#                'address':'/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterNone.pkl'},\n",
        "#               {'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'cropping_rescaling',\n",
        "#                'address': '/content/drive/MyDrive/Colab Notebooks/FalseMean_Filtercropping_rescaling.pkl'}, \n",
        "#               {'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'bit_depth_reduction',\n",
        "#                'address':'/content/drive/MyDrive/Colab Notebooks/FalseMean_Filterbit_depth_reduction.pkl'},\n",
        "#               {'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'JEPG_compression',\n",
        "#                'address': '/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterJEPG_compression.pkl'},\n",
        "#               {'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'TVDenoise',\n",
        "#                'address':'/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterTVDenoise.pkl'}]\n",
        "# epsilon_range = [0.0,5]\n",
        "# plottingAttack(modelsInfo, epsilon_range, testloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modelsInfo = [{'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': None,\n",
        "#                'address':'/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterNone.pkl'},\n",
        "#               {'whether_denoising': True, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'JEPG_compression',\n",
        "#                'address': '/content/drive/MyDrive/Colab Notebooks/TrueMean_FilterJEPG_compression.pkl'}, \n",
        "#               {'whether_denoising': True, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': None,\n",
        "#                'address':'/content/drive/MyDrive/Colab Notebooks/TrueMean_FilterNone.pkl'},\n",
        "#               {'whether_denoising': False, \n",
        "#                'filter_type': 'Mean_Filter', \n",
        "#                'transform': 'JEPG_compression',\n",
        "#                'address': '/content/drive/MyDrive/Colab Notebooks/FalseMean_FilterJEPG_compression.pkl'}]\n",
        "# epsilon_range = [0.0,5]\n",
        "# plottingAttack(modelsInfo, epsilon_range, testloader)"
      ],
      "metadata": {
        "id": "wSb2jtYehuTD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p0sNpua3EuG"
      },
      "source": [
        "# Reference\n",
        "\n",
        "Adversarial attack:\n",
        "* https://github.com/JasonTang99/csc2529_project/blob/main/attack.py\n",
        "* https://github.com/cleverhans-lab/cleverhans/blob/master/cleverhans/jax/attacks/fast_gradient_method.py\n",
        "\n",
        "\n",
        "Countering Adversarial Images Using Input Transformations:\n",
        "* https://github.com/facebookarchive/adversarial_image_defenses\n",
        "* https://arxiv.org/pdf/1812.03411.pdf\n",
        "\n",
        "Data Transformation: \n",
        "* https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n",
        "* JPEG tranformation: https://discuss.pytorch.org/t/how-can-i-develop-a-transformation-that-performs-jpeg-compression-with-a-random-qf/43588/4\n",
        "* TV denoise using bregman algorithm: https://github.com/shakes76/PatternFlow/blob/master/algorithms/denoise/denoise_tv_bregman/denoise_tv_bregman.py\n",
        "\n",
        "Others:\n",
        "* https://github.com/tqdm/tqdm\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}